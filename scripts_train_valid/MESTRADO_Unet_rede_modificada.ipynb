{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOVmEFsVvxkXdhciSTlWgN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnaldojr/powerlinesegmentation/blob/main/MESTRADO_Unet_rede_modificada.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t55iGVNWTs7d"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import datetime\n",
        "\n",
        "import cv2;\n",
        "import numpy as np; np.random.seed(7);\n",
        "import os;\n",
        "import sys;\n",
        "import tensorflow.keras as keras\n",
        "import keras.backend as K;\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcYNDqak7l03"
      },
      "source": [
        "###!pip install tensorboardcolab # to install tensorboeadcolab if it does not it not exist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOHTe_R97pdK",
        "outputId": "e75724c6-8396-4971-e79a-632ec43498ef"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2Gk2yEz7zGN"
      },
      "source": [
        "bdDir = \"/content/drive/MyDrive/USP/unet_segmentation/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
        "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
        "    # first layer\n",
        "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
        "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # second layer\n",
        "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
        "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "-8hAnHWcpE1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
        "    \"\"\"Function to define the UNET Model\"\"\"\n",
        "    # Contracting Path\n",
        "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    p1 = Dropout(dropout)(p1)\n",
        "\n",
        "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    p2 = Dropout(dropout)(p2)\n",
        "\n",
        "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "    p3 = Dropout(dropout)(p3)\n",
        "\n",
        "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "    p4 = Dropout(dropout)(p4)\n",
        "\n",
        "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
        "\n",
        "    # Expansive Path\n",
        "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    u6 = Dropout(dropout)(u6)\n",
        "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
        "\n",
        "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    u7 = Dropout(dropout)(u7)\n",
        "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
        "\n",
        "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    u8 = Dropout(dropout)(u8)\n",
        "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
        "\n",
        "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    u9 = Dropout(dropout)(u9)\n",
        "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "    model = Model(inputs=[input_img], outputs=[outputs])\n",
        "    return model"
      ],
      "metadata": {
        "id": "uv4ZYfIcqdkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set some parameters\n",
        "im_width = 128\n",
        "im_height = 128\n",
        "\n",
        "input_img = Input((im_height, im_width, 1), name='img')\n",
        "model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
        "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "pRdP8FLoqgFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaw4t4RSqxEp",
        "outputId": "f46d1a1d-cb24-4592-c70d-e48434f6992c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " img (InputLayer)               [(None, 128, 128, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 128, 128, 16  160         ['img[0][0]']                    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 128, 128, 16  64         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 128, 128, 16  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 64, 64, 16)   0           ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64, 64, 16)   0           ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 64, 64, 32)   4640        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 64, 64, 32)  128         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 64, 64, 32)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 32)  0           ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 32, 32, 32)   0           ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 32, 32, 64)   18496       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 32, 32, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 64)  0           ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 16, 16, 64)   0           ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 128)  73856       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 128)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 128)   0           ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 8, 8, 128)    0           ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 8, 8, 256)    295168      ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 8, 8, 256)    0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 16, 16, 128)  295040     ['activation_9[0][0]']           \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 16, 16, 256)  0           ['conv2d_transpose[0][0]',       \n",
            "                                                                  'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 16, 16, 256)  0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 128)  295040      ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 128)  512        ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 128)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 32, 32, 64)  73792       ['activation_11[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 32, 32, 128)  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 32, 32, 128)  0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 32, 32, 64)   73792       ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 32, 32, 64)  256         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 64, 64, 32)  18464       ['activation_13[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 64, 64, 64)   0           ['conv2d_transpose_2[0][0]',     \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 64, 64, 64)   0           ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 64, 64, 32)   18464       ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 64, 64, 32)  128         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 64, 64, 32)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 128, 128, 16  4624       ['activation_15[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 128, 128, 32  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                )                                 'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 128, 128, 32  0           ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 128, 128, 16  4624        ['dropout_7[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 128, 128, 16  64         ['conv2d_17[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 128, 128, 16  0           ['batch_normalization_17[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 128, 128, 1)  17          ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,179,121\n",
            "Trainable params: 1,177,649\n",
            "Non-trainable params: 1,472\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCvsLv9kBHod"
      },
      "source": [
        "#### modelo 1 original....\n",
        "\n",
        "def unet(input_size = (128,128,1)):\n",
        "  inputs = Input(input_size) #128x128\n",
        "  conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same' )(inputs)\n",
        "  conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same' )(conv2)\n",
        "\n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)  #64x64\n",
        "  conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same' )(pool2)\n",
        "  conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same' )(conv3)\n",
        "\n",
        "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)  #32x32\n",
        "  conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same' )(pool3)\n",
        "  conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same' )(conv4)\n",
        "  drop4 = Dropout(0.5)(conv4) #32x32\n",
        "\n",
        "  pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)  #16x16\n",
        "\n",
        "  conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same' )(pool4)\n",
        "  conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same' )(conv5)\n",
        "  drop5 = Dropout(0.5)(conv5)   #16x16\n",
        "\n",
        "##expanção\n",
        "\n",
        "  up6 = Conv2D(256, ctivation = 'relu', padding = 'same'\n",
        "              )(UpSampling2D(size = (2,2))(drop5)) #32x32\n",
        "  merge6 = concatenate([drop4,up6], axis = 3)#32x32\n",
        "  conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same' )(merge6)\n",
        "  conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same' )(conv6)\n",
        "\n",
        "\n",
        "  up7 = Conv2D(128, 2, activation = 'relu', padding = 'same'\n",
        "              )(UpSampling2D(size = (2,2))(conv6)) #64x64\n",
        "  merge7 = concatenate([conv3,up7], axis = 3)\n",
        "  conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same' )(merge7)\n",
        "  conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same' )(conv7)\n",
        "\n",
        "\n",
        "  up8 = Conv2D(164, 2, activation = 'relu', padding = 'same'\n",
        "              )(UpSampling2D(size = (2,2))(conv7)) #128x128\n",
        "  merge8 = concatenate([conv2,up8], axis = 3)\n",
        "  conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same' )(merge8)\n",
        "  conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same' )(conv8)\n",
        "  conv8 = Conv2D(2, 3, activation = 'relu', padding = 'same' )(conv8)\n",
        "\n",
        "\n",
        "  conv9 = Conv2D(1, 1, activation = 'sigmoid', padding = 'same',\n",
        "                 bias_initializer=keras.initializers.Constant(value=1.5))(conv8)\n",
        "\n",
        "  model = Model(inputs = inputs, outputs = conv9)\n",
        "\n",
        "  model.compile(optimizer =Adam(lr = 1e-3),\n",
        "                loss = 'mean_squared_error', metrics = ['accuracy'])\n",
        "  return model\n",
        "\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = unet()\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "CqSaD3Nhm7Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98l_eI_rF1By"
      },
      "source": [
        "nomeprog=\"wire_unet_modificado\"\n",
        "train_path='/content/drive/MyDrive/USP/unet_segmentation/train';\n",
        "outDir = \"/content/drive/MyDrive/USP/unet_segmentation/unet_segmentation_out\"; os.chdir(outDir)\n",
        "\n",
        "test_path='/content/drive/MyDrive/USP/unet_segmentation/test';\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeGAW35LHm2a",
        "outputId": "3d96209b-bd6c-48dc-994f-e13d17559915"
      },
      "source": [
        "aug_dict = dict(rotation_range=10, #Int. Degree range for random rotations.\n",
        "  width_shift_range=0.05, #float: fraction of total width, if < 1, or pixels if >= 1.\n",
        "  height_shift_range=0.05, #float: fraction of total height, if < 1, or pixels if >= 1.\n",
        "  shear_range=10, #Float. Shear Intensity (Shear angle in counter-clockwise direction in degrees)\n",
        "  zoom_range=0.2, #Range for random zoom. If a float, [lower, upper] = [1-zoom_range, 1+zoom_range].\n",
        "  horizontal_flip=False, #Boolean. Randomly flip inputs horizontally.\n",
        "  fill_mode='reflect'); #One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}.\n",
        "\n",
        "image_folder='image';\n",
        "mask_folder= 'label';\n",
        "target_size = (128,128);\n",
        "batch_size=10;\n",
        "seed = 7;\n",
        "save_to_dir = None;\n",
        "\n",
        "image_datagen = ImageDataGenerator(**aug_dict);\n",
        "mask_datagen = ImageDataGenerator(**aug_dict);\n",
        "\n",
        "image_generator = image_datagen.flow_from_directory(\n",
        "  train_path,\n",
        "  classes = [image_folder],\n",
        "  class_mode = None,\n",
        "  color_mode = \"grayscale\",\n",
        "  target_size = target_size,\n",
        "  batch_size = batch_size,\n",
        "  seed = seed);\n",
        "\n",
        "mask_generator = mask_datagen.flow_from_directory(\n",
        "  train_path,\n",
        "  classes = [mask_folder],\n",
        "  class_mode = None,\n",
        "  color_mode = \"grayscale\",\n",
        "  target_size = target_size,\n",
        "  batch_size = batch_size,\n",
        "  seed = seed);\n",
        "\n",
        "def trainGenerator():\n",
        "  train_generator=zip(image_generator,mask_generator)\n",
        "  for (img,mask) in train_generator:\n",
        "    img=img/255\n",
        "    mask=mask/255\n",
        "    mask[mask > 0.5] = 1\n",
        "    mask[mask <= 0.5] = 0\n",
        "    yield(img,mask)\n",
        "\n",
        "def validationGenerator():\n",
        "  train_generator=zip(image_generator,mask_generator)\n",
        "  for (img,mask) in train_generator:\n",
        "    img=img/255\n",
        "    mask=mask/255\n",
        "    mask[mask > 0.5] = 1\n",
        "    mask[mask <= 0.5] = 0\n",
        "    yield(img,mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 images belonging to 1 classes.\n",
            "Found 100 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=10, verbose=1),\n",
        "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n",
        "    ModelCheckpoint('model-modificado.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "]"
      ],
      "metadata": {
        "id": "adAlxL60VJcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(trainGenerator(), batch_size=32, epochs=50, callbacks=callbacks,\\\n",
        "                    validation_data=trainGenerator())\n",
        "\n",
        "#history=  model.fit(trainGenerator(),steps_per_epoch=30,epochs=100,verbose=1);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mONGSK7VNtN",
        "outputId": "c526c650-c05a-4422-c3c2-4d031e571f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "  25897/Unknown - 3004s 116ms/step - loss: 0.0605 - accuracy: 0.9750"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVliVoQXIRGR"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "#<<<<<<<<<<<<<<<<< main <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "#comecar treino do zero\n",
        "#model = unet();\n",
        "#model = load_model(nomeprog+\".h5\");\n",
        "\n",
        "#plot_model(model, to_file='unet-train1.png', show_shapes=True)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history=model.fit(trainGenerator(),steps_per_epoch=30,epochs=100,verbose=1);\n",
        "\n",
        "#history=model.fit(x_train,\n",
        "#          y_train,\n",
        "#          batch_size=30,\n",
        "#          epochs=100,\n",
        "#          verbose=2,\n",
        "#          validation_data=(x_val, y_val))\n",
        "\n",
        "\n",
        "\n",
        "#model.save(nomeprog+\"2.h5\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcwqvHGkdghE"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#accuracy = model.evaluate(x_val, y_val)\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "#val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "#plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPAjoqqYLr5p"
      },
      "source": [
        "#testa1.py\n",
        "import cv2;\n",
        "import numpy as np; np.random.seed(7);\n",
        "import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
        "import sys;\n",
        "import tensorflow.keras as keras\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras import backend as keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUjfxCTTQsZt",
        "outputId": "bbd38ab6-5b7a-41d5-ab89-85760c79ab55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze9S3JvWLwvs"
      },
      "source": [
        "def leUmDir(imagePath):\n",
        "  #Le imagens em um diretorio e retorna como float32 entre 0 e +1\n",
        "  #Tambem retorna os nomes das imagens\n",
        "  imageList = [f for f in os.listdir(imagePath) if os.path.isfile(os.path.join(imagePath, f))];\n",
        "  imageList.sort();\n",
        "  n=len(imageList);\n",
        "\n",
        "  nl,nc = 128,128;\n",
        "  AX=np.empty((n,nl,nc),dtype='uint8')\n",
        "\n",
        "  for i in range(n):\n",
        "    t=cv2.imread(os.path.join(imagePath, imageList[i]),0);\n",
        "    t=cv2.resize(t,(nc,nl),interpolation=cv2.INTER_AREA);\n",
        "    AX[i,:]=t;\n",
        "\n",
        "  ax = np.float32(AX)/255.0; #Entre 0 e +1\n",
        "  ax = ax.reshape(n, nl, nc, 1);\n",
        "  return ax, imageList, AX;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjTR461jL3ne"
      },
      "source": [
        "test_path='/content/drive/MyDrive/USP/unet_segmentation/test/image';\n",
        "label_path='/content/drive/MyDrive/USP/unet_segmentation/test/label2';\n",
        "outDir = \"/content/drive/MyDrive/USP/unet_segmentation/unet_segmentation_out\"; os.chdir(outDir)\n",
        "\n",
        "#model=load_model(\"wire_unet2.h5\");\n",
        "ax, imageList, AX = leUmDir(test_path);\n",
        "ax_label, imageList_label, AX_label = leUmDir(label_path);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(imageList))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAwWn4OgS4x8",
        "outputId": "96aaef3b-cab1-4516-8e7d-4be579bafcff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkUJqeSNMMtr"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "results = model.predict(ax,verbose=1); #Entre 0 e 1\n",
        "results = results[:,:,:,0]\n",
        "results = 255*results\n",
        "results = np.clip(results,0,255);\n",
        "qp=results.astype(np.uint8);\n",
        "j=1\n",
        "plt.figure(figsize = (5,30))\n",
        "for i in range(len(imageList)):\n",
        "  ## entrada\n",
        "  plt.subplot(20,3,j)\n",
        "  plt.imshow(AX[i],cmap=\"gray\")\n",
        "  plt.axis('off')\n",
        "  j=j+1\n",
        "  ##label\n",
        "  plt.subplot(20,3,j)\n",
        "  plt.imshow(AX_label[i],cmap=\"gray\")\n",
        "  plt.axis('off')\n",
        "  j=j+1\n",
        "  ##predição\n",
        "  plt.subplot(20,3,j)\n",
        "  plt.imshow(qp[i],cmap=\"gray\")\n",
        "  plt.axis('off')\n",
        "  j=j+1\n",
        "plt.show()\n",
        "\n",
        "for i in range(len(imageList)):\n",
        "  cv2.imwrite(imageList[i],qp[i]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgEntrada = AX[0]\n",
        "imgLabel = AX_label[0]\n",
        "imgOut = qp[0]\n",
        "imgOutinv = 255 - imgOut\n",
        "\n",
        "contornos, _ = cv2.findContours(imgOutinv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "mask_rgb = cv2.cvtColor(imgOutinv, cv2.COLOR_GRAY2RGB)\n",
        "contornos_img = mask_rgb.copy() # Cópia da máscara para ser desenhada \"por cima\"\n",
        "\n",
        "cv2.drawContours(contornos_img, contornos, -1, [255, 0, 0], 1);\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.imshow(contornos_img);\n",
        "\n"
      ],
      "metadata": {
        "id": "p1xiHPzOlaRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "imgSaida = cv2.bitwise_and(imgLabel, imgOutinv)\n",
        "imgSaida2 = cv2.bitwise_or(imgLabel, imgOutinv)\n",
        "imgSaida3 = cv2.bitwise_xor(imgLabel, imgOutinv)\n",
        "\n",
        "plt.imshow(imgSaida)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_uzAtMD2sByi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78mFd_0E4Z2t",
        "outputId": "fa5f0a93-a233-4b84-d646-ecefd3e75574"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "print(sys.version)\n",
        "print(\"Versao de tensorflow:\",tf.__version__)\n",
        "print(\"Versao de Keras independente:\",keras.__version__)\n",
        "print(\"Versao de Keras dentro de tensorflow:\",tf.keras.__version__)\n",
        "print(\"Versao cv2:\",cv2.__version__)\n",
        "print()\n",
        "\n",
        "gpu=tf.test.gpu_device_name()\n",
        "if gpu==\"\":\n",
        "  print(\"Computador sem GPU.\")\n",
        "else:\n",
        "  print(\"Computador com GPU:\",tf.test.gpu_device_name())\n",
        "  from tensorflow.python.client import device_lib\n",
        "  devices=device_lib.list_local_devices()\n",
        "  print(\"Dispositivos:\",[x.physical_device_desc for x in devices if x.physical_device_desc!=\"\"])\n",
        "print()\n",
        "\n",
        "!lsb_release -a | grep \"Description\" #imprime qual é o sistema operacional\n",
        "!echo\n",
        "\n",
        "!cat /proc/cpuinfo | grep -E \"model name|core\" #especificações de CPU\n",
        "!echo\n",
        "\n",
        "!cat /proc/meminfo | grep \"Mem\" #especificações de RAM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.9 (default, Oct  8 2020, 12:12:24) \n",
            "[GCC 8.4.0]\n",
            "Versao de tensorflow: 2.3.0\n",
            "Versao de Keras independente: 2.4.3\n",
            "Versao de Keras dentro de tensorflow: 2.4.0\n",
            "Versao cv2: 4.1.2\n",
            "\n",
            "Computador com GPU: /device:GPU:0\n",
            "Dispositivos: ['device: XLA_CPU device', 'device: XLA_GPU device', 'device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5']\n",
            "\n",
            "No LSB modules are available.\n",
            "Description:\tUbuntu 18.04.5 LTS\n",
            "\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "\n",
            "MemTotal:       13333580 kB\n",
            "MemFree:         6192280 kB\n",
            "MemAvailable:   10517456 kB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################################################################3\n",
        "\n",
        "### visualização intermediaria\n",
        "\n",
        "#####################################################################################################3333"
      ],
      "metadata": {
        "id": "ztuyWdfJEZPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "VRJojEm8EfKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_names = [layer.name for layer in model.layers]\n",
        "layer_names"
      ],
      "metadata": {
        "id": "uRlkovbiEqGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "metadata": {
        "id": "2wCzbk1GEwDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "layer_outputs"
      ],
      "metadata": {
        "id": "Xkzxc_sBE1KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(model.layers)):\n",
        "    layer = model.layers[i]\n",
        "    if 'conv' not in layer.name:\n",
        "        continue\n",
        "    print(i , layer.name , layer.output.shape)"
      ],
      "metadata": {
        "id": "tMkNjesbI7BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=model.inputs , outputs=model.layers[1].output)"
      ],
      "metadata": {
        "id": "1UywCZstJAwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from numpy import expand_dims\n",
        "import cv2\n",
        "image = load_img(\"/content/drive/MyDrive/USP/unet_segmentation/test/image/574.jpg\" ,grayscale=True, target_size=(128,128))\n",
        "# convert the image to an array\n",
        "image = img_to_array(image)\n",
        "# expand dimensions so that it represents a single 'sample'\n",
        "image = expand_dims(image, axis=0)\n",
        "#image=cv2.resize(image,(128,128),interpolation=cv2.INTER_AREA);\n",
        "image.shape"
      ],
      "metadata": {
        "id": "8VOohGDcJFn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating features_map\n",
        "features = model.predict(image)\n",
        "\n",
        "fig = plt.figure(figsize=(20,15))\n",
        "for i in range(1,features.shape[3]+1):\n",
        "\n",
        "    plt.subplot(10,10,i)\n",
        "    plt.imshow(features[0,:,:,i-1] , cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iCI5GWZQJKmB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}